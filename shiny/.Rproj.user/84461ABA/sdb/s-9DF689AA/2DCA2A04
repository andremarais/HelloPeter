{
    "contents" : "require(RCurl)\nrequire(XML)\nrequire(wordcloud)\nrequire(plyr)\nrequire(ggplot2)\nrequire(stringr)\n\ntrim.leading <- function (x)  sub(\"^\\\\s+\", \"\", x)\ntrim.trailing <- function (x) sub(\"\\\\s+$\", \"\", x)\ncleanFun <- function(htmlString) {\n  return(gsub(\"<.*?>\", \"\", htmlString))\n}\nstripwhitespace <- function(x) gsub(\"^\\\\s+|\\\\s+$\", \"\", x)\n\n\n\nhp <- c()\nlink <- data.frame()\ntitle <- data.frame()\ntime <- data.frame()\ntype <- data.frame()\npost <- data.frame()\npostbody <- data.frame()\nresponse.date <- data.frame()\nall.data <- list()\nnature <- data.frame()\n\n# Momentum\nMomHealth <- \"http://hellopeter.com/momentum-health/compliments-and-complaints?country=South%20Africa&pg=\"\nMomentum <- \"http://hellopeter.com/momentum/compliments-and-complaints?country=South%20Africa&pg=\"\nMSTI <- \"http://hellopeter.com/momentum-short-term-insurance/compliments-and-complaints?country=South%20Africa&pg=\"\n\n# Discovery\nDiscHealth <- \"http://hellopeter.com/discovery-health/compliments-and-complaints?country=South%20Africa&pg=\"\nDiscLife <- \"http://hellopeter.com/discovery-life/compliments-and-complaints?country=South%20Africa&pg=\"\nDiscInsure <- \"http://hellopeter.com/discovery-insure/compliments-and-complaints?country=South%20Africa&pg=\"\n\n# Old Mutual\nOM <- \"http://hellopeter.com/old-mutual/compliments-and-complaints?country=South%20Africa&pg=\"\n\n#Liberty\nLibertyLife <- \"http://hellopeter.com/liberty-life/compliments-and-complaints?country=South%20Africa&pg=\"\n\n# Metropolitan\nMetro <- \"http://hellopeter.com/metropolitan-life/compliments-and-complaints?country=South%20Africa&pg=\"\n\n#Outsurance\nOutsurance <- \"http://hellopeter.com/outsurance/compliments-and-complaints?country=South%20Africa&pg=\"\n\n#MiWay\nMiway <- \"http://hellopeter.com/miway/compliments-and-complaints?country=South%20Africa&pg=\"\n\n\n\n\ninsurers <- data.frame(MomHealth, Momentum, MSTI,\n              DiscHealth, DiscLife, DiscInsure,\n              OM,\n              LibertyLife,\n              Metro,\n              Outsurance,\n              Miway)\n\ninsurar.names <- c(\"Momentum Health\", \"Momentum\", \"Momentum Short Term\",\n                   \"Discovery Health\", \"Discovery Life\", \"Discovery Insure\",\n                   \"Old Mutual\",\n                   \"Liberty\",\n                   \"Metropolitan\",\n                   \"OutSurance\",\n                   \"MiWay\")\n\n\n## BEGIN HIERSO POES!!!\nsystem.time(\n  for (h in 1:length(insurers)) {\n  #for (h in 1:3) {\n    \n    \n    hp[1] <- httpGET(paste(insurers[1,h], 1, sep = \"\"))\n    \n    \n    \n    #gets last page\n    lpsnippet <- substring(hp[1], gregexpr(\">>\", hp[1])[[1]][1], gregexpr(\">>\", hp[1])[[1]][2])\n    if(is.na(lpsnippet)) pages <- 1 else {\n      a <- as.numeric(regexpr(\"pg=\",lpsnippet)[[1]] + attr(gregexpr(\"pg=\",lpsnippet)[[1]], \"match.length\"))\n      b <- min(gregexpr(\"\\\"\",lpsnippet)[[1]][which(gregexpr(\"\\\"\",lpsnippet)[[1]] > gregexpr(\"pg=\",lpsnippet)[[1]][1])]) -1\n      pages <- as.numeric(substring(lpsnippet, a, b))\n    }\n    \n    \n    for (i in 1:pages){\n      hp[i] <- httpGET(paste(insurers[1,h], i, sep = \"\"))\n      print(i)\n      \n    }\n    \n    \n    # Run this\n    \n    for (i in 1:pages) {\n      linklocations <- gregexpr(\"<div class=\\\"td-item2\\\"><a class=\\\"fb-link\\\"\", hp[i])\n      for (j in 1:length(linklocations[[1]])) {\n        \n        #gets URL\n        snippet <- substring(hp[i],\n                             linklocations[[1]][j],\n                             if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])\n        \n        # Link\n        link[j,i] <- substring(snippet, gregexpr(\"href=\\\"\",snippet)[[1]][1] + 6,gregexpr(\" title=\\\"\",snippet)[[1]][1]-2)\n        \n        # Title\n        a <- gregexpr(\"title=\\\"\",snippet)[[1]][1] + 7\n        b <- min(gregexpr(\"\\\">\",snippet)[[1]][which(gregexpr(\"\\\">\",snippet)[[1]] > gregexpr(\"title=\\\"\",snippet)[[1]][1] + 7)])-1\n        title[j,i] <- substring(snippet, a, b)\n        \n        # Time of post\n        a <- gregexpr(\"\\\">\\t\",snippet)[[1]][1] + 7\n        b <- min(gregexpr(\"\\t\",snippet)[[1]][which(gregexpr(\"\\t\",snippet)[[1]] > gregexpr(\"\\\">\\t\",snippet)[[1]][1] + 7)])-1\n        c <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = \"%H:%M:%S %A %d %b %y\"))\n        d <- str_match(snippet, \"[0-9]{2}:[0-9]{2}:[0-9]{2}\")[1,1]\n        time[j,i] <- as.POSIXct(paste(c, d), tz = \"GMT\")\n        \n        \n        # Type of post\n        if (regexpr(\"complaints/\", link[j,i], ignore.case = T) != -1) type[j,i] <- \"Complaint\" \n        if (regexpr(\"compliments/\", link[j,i], ignore.case = T) != -1) type[j,i] <- \"Compliment\" \n        if (regexpr(\"complaints-to-compliments/\", link[j,i], ignore.case = T) != -1) type[j,i] <- \"Conversion\"\n        \n        # Response time\n        if (!is.na(link[j,i])) {\n          post[j,i] <- httpGET(link[j,i])\n          a <- min(gregexpr(\"SUPPLIER'S RESPONSE\", post[j,i])[[1]])\n          if (a == -1)  response.date[j,i] <- 0 else {\n            \n            b <- min(gregexpr(\"[0-9]{2}:[0-9]{2}:[0-9]{2}\", substring(post[j,i], a, a + 500))[[1]])\n            c <- min(gregexpr(\"</td>\", substring(post[j,i], a + b , a + b + 60))[[1]])\n            d <- substring(post[j,i], a + b -1, a +  b + c-2)\n            e <- as.Date(as.character(d), format = \"%H:%M:%S | %a %d %b %y\")\n            f <- str_match(substring(post[j,i], a, a + 500), \"[0-9]{2}:[0-9]{2}:[0-9]{2}\")[1,1]\n            response.date[j,i] <- as.POSIXct(paste(e, f), tz = \"GMT\")\n            \n            #Nature of post\n            if (type[j,i] == \"Compliment\" ) look.for <- \"NATURE\"  else look.for <- \"PROBLEM\"\n            a <- min(gregexpr(look.for, post[j,i], ignore.case = F)[[1]]) + attr(gregexpr(look.for, post[j,i], ignore.case = F)[[1]], \"match.length\")[1]\n            b <- min(gregexpr(\"tbl-txt-hd-nb\\\"\", substring(post[j,i], a, a + 200))[[1]]) + attr(gregexpr(\"tbl-txt-hd-nb\\\"\", substring(post[j,i], a, a + 200))[[1]], \"match.length\")[1]\n            c <- min(gregexpr(\"</h3>\", substring(post[j,i], a + b, a + b + 200))[[1]]) \n            nature[j,i] <- substring(post[j,i], a + b, a+b+c -2)\n            \n            # acutal post\n            a <- gregexpr(\"shade border justify\\\">\\n\\t\\t\\t\\t\", post[j,i])\n            b <- gregexpr(\"<div class=\\\"report-action\\\">\", post[j,i])\n            post[j,i] <- substring(post[j,i], as.numeric(a) + attr(a[[1]], \"match.length\"), as.numeric(b) -1)\n            post[j,i] <- gsub(\"\\n\", \"\", post[j,i])\n            post[j,i] <- gsub(\"\\t\", \"\", post[j,i])\n            post[j,i] <- stripwhitespace(post[j,i])\n            \n            \n            \n            \n            \n            \n          }             \n        }\n        \n        \n        \n        \n        \n        print(c(h,i,j))\n      }\n    }\n    \n    time.vector <- as.vector(as.matrix(time))\n    type.vector <- as.vector(as.matrix(type))\n    response.date.vector <- as.vector(as.matrix(response.date))\n    nature.vector <- as.vector(as.matrix(nature))\n    post.vector <- as.vector(as.matrix(post))\n    \n    hp.df <- data.frame(cbind(insurers[h], insurar.names[h], time.vector, type.vector, response.date.vector, nature.vector, post.vector))\n    colnames(hp.df) <- c(\"Insurer\", \"Insurer.proper.name\", \"post.date\", \"type\", \"response.date\", \"nature\", \"content\")\n    hp.df <- hp.df[!is.na(hp.df$post.date),]\n    \n    all.data[[h]] <- hp.df\n    saveRDS(hp.df, file = paste(insurar.names[h],\".RDS\", sep = \"\"))\n    \n  }\n)\n\n\n\n\n\n\n",
    "created" : 1431693458496.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1230910638",
    "id" : "2DCA2A04",
    "lastKnownWriteTime" : 1431793689,
    "path" : "~/GitHub/HelloPeter/shiny/HPcrawler.R",
    "project_path" : "HPcrawler.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}