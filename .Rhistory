snippet
hp[i]
linklocations[[1]]
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
linklocations[[1]]
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
substring(snippet, a, b)
gregexpr("http://hellopeter.com/images/icons/complaint.png", snippet)
snippet
substring(snippet, a, b)
j <- j
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
gregexpr("http://hellopeter.com/images/icons/complaint.png", snippet)
#
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
title[j,i]
link[j,i]
snippet
link[j,i]
link[6,1]
gregexpr("\">\t", snippet)
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
gregexpr("http://hellopeter.com/images/icons/complaint.png", snippet)
#
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
}
}
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
substring(snippet, a, b)
trim.leading <- function (x)  sub("^\\s+", "", x)
trim.trailing <- function (x) sub("\\s+$", "", x)
trim.leading(substring(snippet, a, b))
format( trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
str(format( trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
data(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
str(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
regexpr("complaints", link[j,i], ignore.case = T)
link[j,i]
j
j <- 7
link[j,i]
link[,1]
i
i <- 1
link[j,i]
regexpr("complaints", link[j,i], ignore.case = T)
?regexpr
regexpr("complaints", link[j,i], ignore.case = T, fixed = T)
regexpr("complaints//", link[j,i], ignore.case = T)
regexpr("complaints/", link[j,i], ignore.case = T)
j <- 8
regexpr("complaints/", link[j,i], ignore.case = T
)
link[j,i]
j <- 6
regexpr("complaints/", link[j,i], ignore.case = T)
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint" else 0
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion" else 0
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint" else 0
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint" else 0
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion" else 0
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint" else 0
}
}
time <- data.frame()
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint" else 0
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion" else 0
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint" else 0
}
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint" else  type[j,i] <- 0
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion" else type[j,i] <- 0
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment" else type[j,i] <- 0
}
}
type <- data.frame()
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint" else  type[j,i] <- 0
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion" else type[j,i] <- 0
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment" else type[j,i] <- 0
}
}
type
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
}
}
type
time
str(time)
as.Date(time)
as.Date(time, format = "%Y%m%d")
as.Date(time[1,2])
as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
time <- data.frame(as.Date())
time <- as.Date(data.frame())
as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
time[j,i] <- as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y")
time[j,i]
as.Date(time[j,i])
?as.Date
as.Date(as.character(trim.leading(substring(snippet, a, b))), format = "%H:%M:%S %A %d %b %y")
time[j,i] <- as.Date(as.character(trim.leading(substring(snippet, a, b))), format = "%H:%M:%S %A %d %b %y")
time[j,i]
as.Date(time[i,j], format = "%Y%m%d")
as.Date(time[i,j], format = "%Y%M%d")
as.Date(time[i,j], format = "%Y%M%d", origin)
as.Date(time[i,j], format = "%Y%M%d", origin = type[j,i] <-)
as.Date(time[i,j], format = "%Y%M%d", origin = "1900-01-01")
as.Date(time[i,j], origin = "1900-01-01")
as.Date(time[i,j], origin = "1950-01-01")
as.Date(time[i,j], origin = "1970-01-01")
as.Date(time[i,j], origin = "1971-01-01")
as.Date(time[i,j], origin = "1970-06-01")
as.Date(time[i,j], origin = "1969-06-01")
as.Date(time[i,j], origin = "1969-04-01")
as.character(as.Date(as.character(trim.leading(substring(snippet, a, b))), format = "%H:%M:%S %A %d %b %y"))
time[j,i] <- as.character(as.Date(as.character(trim.leading(substring(snippet, a, b))), format = "%H:%M:%S %A %d %b %y"))
time[j,i]
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
}
}
[j,i]
time
links
link
link[,8]
!is.na(link)
which(is.na(link))
which(!is.na(link))
link[!is.na(link)]
data.frame()ink[!is.na(link)]
data.frame(link[!is.na(link)])
link
link[!is.na(link)]
link
link[!is.na(link)]
postbody <- data.frame()
httpGET("http://hellopeter.com/momentum/complaints/paid-my-pension-to-sars-1358484")
httpGET("http://hellopeter.com/momentum/compliments/excellent-service-1655775")
link
require(RCurl)
require(XML)
trim.leading <- function (x)  sub("^\\s+", "", x)
trim.trailing <- function (x) sub("\\s+$", "", x)
cleanFun <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
hp <- c()
link <- data.frame()
title <- data.frame()
time <- data.frame()
type <- data.frame()
postbody <- data.frame()
txt <- "\\(Supplier name changed from.*\\)"
hp[1] <- httpGET("http://hellopeter.com/momentum/compliments-and-complaints?country=South%20Africa&pg=1")
#gets last page
lpsnippet <- substring(hp[1], gregexpr(">>", hp[1])[[1]][1], gregexpr(">>", hp[1])[[1]][2])
a <- as.numeric(regexpr("pg=",lpsnippet)[[1]] + attr(gregexpr("pg=",lpsnippet)[[1]], "match.length"))
b <- min(gregexpr("\"",lpsnippet)[[1]][which(gregexpr("\"",lpsnippet)[[1]] > gregexpr("pg=",lpsnippet)[[1]][1])]) -1
pages <- as.numeric(substring(lpsnippet, a, b))
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/momentum/compliments-and-complaints?country=South%20Africa&pg=", i, sep = ""))
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
}
print(c(i,j))
}
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
}
print(c(i,j))
}
}
postbody
to.remove
gsub("\t", "", postbody)
gsub("\\t", "", postbody)
postbody
postbody[8,3]
m <- postbody[8,3]
mn
m
gsub("\n", "", m)
postbody[,1]
gsub("\n", "", postbody[,1])
gsub("\t", "",gsub("\n", "", postbody[,1]))
gsub("\t", "",gsub("\n", "", postbody[,]))
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}}
postbody
to.remove
wordcloud(postbody)
require(wordcloud)
View(postbody)
wordcloud(postbody)
?save
wordcloud(postbody, file = "Momentumpostbody")
save(postbody, file = "Momentumpostbody")
a <- load(postbody)
?load
a <- data.frame(load(postbody))
a <- load("postbody")
getwd()
saveRDS(postbody, "postbody.rds")
setwd("C:/Users/Veldrin/Documents/GitHub/USClientGeomapping")
trim.trailing <- function (x) sub("\\s+$", "", x)
setwd("C:/Users/Veldrin/Documents/GitHub/USClientGeomapping")
ClientAddresses <- read.csv("MyriadClientAddresses.csv")
geo.today <- which(is.na(ClientAddresses$last.update))
ClientAddresses <- ClientAddresses[,!grepl("X", colnames(ClientAddresses))]
loc <- list()
for (i in 1:2500){
loc[[i]] <- geocode(as.character(paste(trim.trailing(ClientAddresses$unique.MClients2.address.[geo.today[i]]), "South Africa", sep = ", ")), output = 'more', override_limit = T)
ClientAddresses$lon[geo.today[i]] <- loc[[i]]$lon
ClientAddresses$lat[geo.today[i]] <- loc[[i]]$lat
if(is.null(loc[[i]]$country)) ClientAddresses$country[geo.today[i]] <- NA else ClientAddresses$country[geo.today[i]] <- loc[[i]]$country
if(is.null(loc[[i]]$administrative_area_level_1)) ClientAddresses$province[geo.today[i]] <- NA else ClientAddresses$province[geo.today[i]] <- loc[[i]]$administrative_area_level_1
ClientAddresses$last.update[geo.today[i]] <- Sys.time()
print(i)
}
write.csv(ClientAddresses, "MyriadClientAddresses.csv")
require(ggmap)
loc <- list()
for (i in 1:2500){
loc[[i]] <- geocode(as.character(paste(trim.trailing(ClientAddresses$unique.MClients2.address.[geo.today[i]]), "South Africa", sep = ", ")), output = 'more', override_limit = T)
ClientAddresses$lon[geo.today[i]] <- loc[[i]]$lon
ClientAddresses$lat[geo.today[i]] <- loc[[i]]$lat
if(is.null(loc[[i]]$country)) ClientAddresses$country[geo.today[i]] <- NA else ClientAddresses$country[geo.today[i]] <- loc[[i]]$country
if(is.null(loc[[i]]$administrative_area_level_1)) ClientAddresses$province[geo.today[i]] <- NA else ClientAddresses$province[geo.today[i]] <- loc[[i]]$administrative_area_level_1
ClientAddresses$last.update[geo.today[i]] <- Sys.time()
print(i)
}
write.csv(ClientAddresses, "MyriadClientAddresses.csv")
require(RCurl)
require(XML)
require(wordcloud)
trim.leading <- function (x)  sub("^\\s+", "", x)
trim.trailing <- function (x) sub("\\s+$", "", x)
cleanFun <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
hp <- c()
link <- data.frame()
title <- data.frame()
time <- data.frame()
type <- data.frame()
postbody <- data.frame()
txt <- "\\(Supplier name changed from.*\\)"
hp[1] <- httpGET("http://hellopeter.com/momentum/compliments-and-complaints?country=South%20Africa&pg=1")
#gets last page
lpsnippet <- substring(hp[1], gregexpr(">>", hp[1])[[1]][1], gregexpr(">>", hp[1])[[1]][2])
a <- as.numeric(regexpr("pg=",lpsnippet)[[1]] + attr(gregexpr("pg=",lpsnippet)[[1]], "match.length"))
b <- min(gregexpr("\"",lpsnippet)[[1]][which(gregexpr("\"",lpsnippet)[[1]] > gregexpr("pg=",lpsnippet)[[1]][1])]) -1
pages <- as.numeric(substring(lpsnippet, a, b))
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/momentum/compliments-and-complaints?country=South%20Africa&pg=", i, sep = ""))
print(i)
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}
print(c(i,j))
}
}
Momentum <- list(time, type, postbody)
setwd("C:/Users/Veldrin/Documents/GitHub/HelloPeter")
saveRDS(Momentum, "Momentum.rds")
Momentum
str(Momentum)
