# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
}
}
[j,i]
time
links
link
link[,8]
!is.na(link)
which(is.na(link))
which(!is.na(link))
link[!is.na(link)]
data.frame()ink[!is.na(link)]
data.frame(link[!is.na(link)])
link
link[!is.na(link)]
link
link[!is.na(link)]
postbody <- data.frame()
httpGET("http://hellopeter.com/momentum/complaints/paid-my-pension-to-sars-1358484")
httpGET("http://hellopeter.com/momentum/compliments/excellent-service-1655775")
link
require(RCurl)
require(XML)
trim.leading <- function (x)  sub("^\\s+", "", x)
trim.trailing <- function (x) sub("\\s+$", "", x)
cleanFun <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
hp <- c()
link <- data.frame()
title <- data.frame()
time <- data.frame()
type <- data.frame()
postbody <- data.frame()
txt <- "\\(Supplier name changed from.*\\)"
hp[1] <- httpGET("http://hellopeter.com/momentum/compliments-and-complaints?country=South%20Africa&pg=1")
#gets last page
lpsnippet <- substring(hp[1], gregexpr(">>", hp[1])[[1]][1], gregexpr(">>", hp[1])[[1]][2])
a <- as.numeric(regexpr("pg=",lpsnippet)[[1]] + attr(gregexpr("pg=",lpsnippet)[[1]], "match.length"))
b <- min(gregexpr("\"",lpsnippet)[[1]][which(gregexpr("\"",lpsnippet)[[1]] > gregexpr("pg=",lpsnippet)[[1]][1])]) -1
pages <- as.numeric(substring(lpsnippet, a, b))
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/momentum/compliments-and-complaints?country=South%20Africa&pg=", i, sep = ""))
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
}
print(c(i,j))
}
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
}
print(c(i,j))
}
}
postbody
to.remove
gsub("\t", "", postbody)
gsub("\\t", "", postbody)
postbody
postbody[8,3]
m <- postbody[8,3]
mn
m
gsub("\n", "", m)
postbody[,1]
gsub("\n", "", postbody[,1])
gsub("\t", "",gsub("\n", "", postbody[,1]))
gsub("\t", "",gsub("\n", "", postbody[,]))
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}}
postbody
to.remove
wordcloud(postbody)
require(wordcloud)
View(postbody)
wordcloud(postbody)
?save
wordcloud(postbody, file = "Momentumpostbody")
save(postbody, file = "Momentumpostbody")
a <- load(postbody)
?load
a <- data.frame(load(postbody))
a <- load("postbody")
getwd()
saveRDS(postbody, "postbody.rds")
gc()
readRDS("postbody.rds")
postbody <- readRDS("postbody.rds")
?save
?saveRDS
hp[1] <- httpGET("http://hellopeter.com/miway?country=South%20Africa&pg=1")
#gets last page
lpsnippet <- substring(hp[1], gregexpr(">>", hp[1])[[1]][1], gregexpr(">>", hp[1])[[1]][2])
a <- as.numeric(regexpr("pg=",lpsnippet)[[1]] + attr(gregexpr("pg=",lpsnippet)[[1]], "match.length"))
b <- min(gregexpr("\"",lpsnippet)[[1]][which(gregexpr("\"",lpsnippet)[[1]] > gregexpr("pg=",lpsnippet)[[1]][1])]) -1
pages <- as.numeric(substring(lpsnippet, a, b))
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/miway?country=South%20Africa&pg=", i, sep = ""))
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}
print(c(i,j))
}
}
hp <- c()
link <- data.frame()
title <- data.frame()
time <- data.frame()
type <- data.frame()
postbody <- data.frame()
txt <- "\\(Supplier name changed from.*\\)"
hp[1] <- httpGET("http://hellopeter.com/miway?country=South%20Africa&pg=1")
#gets last page
lpsnippet <- substring(hp[1], gregexpr(">>", hp[1])[[1]][1], gregexpr(">>", hp[1])[[1]][2])
a <- as.numeric(regexpr("pg=",lpsnippet)[[1]] + attr(gregexpr("pg=",lpsnippet)[[1]], "match.length"))
b <- min(gregexpr("\"",lpsnippet)[[1]][which(gregexpr("\"",lpsnippet)[[1]] > gregexpr("pg=",lpsnippet)[[1]][1])]) -1
pages <- as.numeric(substring(lpsnippet, a, b))
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/miway?country=South%20Africa&pg=", i, sep = ""))
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}
print(c(i,j))
}
}
hp[1] <- httpGET("http://hellopeter.com/miway?country=South%20Africa&pg=1")
require(XML)
require(RCurl)
require(wordcloud)
txt <- "\\(Supplier name changed from.*\\)"
hp[1] <- httpGET("http://hellopeter.com/miway?country=South%20Africa&pg=1")
#gets last page
lpsnippet <- substring(hp[1], gregexpr(">>", hp[1])[[1]][1], gregexpr(">>", hp[1])[[1]][2])
a <- as.numeric(regexpr("pg=",lpsnippet)[[1]] + attr(gregexpr("pg=",lpsnippet)[[1]], "match.length"))
b <- min(gregexpr("\"",lpsnippet)[[1]][which(gregexpr("\"",lpsnippet)[[1]] > gregexpr("pg=",lpsnippet)[[1]][1])]) -1
pages <- as.numeric(substring(lpsnippet, a, b))
pages
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/miway?country=South%20Africa&pg=", i, sep = ""))
}
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/miway?country=South%20Africa&pg=", i, sep = ""))
print(i)
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}
print(c(i,j))
}
}
trim.leading <- function (x)  sub("^\\s+", "", x)
trim.trailing <- function (x) sub("\\s+$", "", x)
cleanFun <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}
print(c(i,j))
}
}
?saveRDS
saveRDS(postbody, "MiWay.rds")
getwd()
setwd("C:/Users/Veldrin/Documents/GitHub/HelloPeter")
hp <- c()
link <- data.frame()
title <- data.frame()
time <- data.frame()
type <- data.frame()
postbody <- data.frame()
txt <- "\\(Supplier name changed from.*\\)"
hp[1] <- httpGET("http://hellopeter.com/discovery-health/compliments-and-complaints?country=South%20Africa&pg=1")
#gets last page
lpsnippet <- substring(hp[1], gregexpr(">>", hp[1])[[1]][1], gregexpr(">>", hp[1])[[1]][2])
a <- as.numeric(regexpr("pg=",lpsnippet)[[1]] + attr(gregexpr("pg=",lpsnippet)[[1]], "match.length"))
b <- min(gregexpr("\"",lpsnippet)[[1]][which(gregexpr("\"",lpsnippet)[[1]] > gregexpr("pg=",lpsnippet)[[1]][1])]) -1
pages <- as.numeric(substring(lpsnippet, a, b))
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/discovery-health/compliments-and-complaints?country=South%20Africa&pg=", i, sep = ""))
print(i)
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}
print(c(i,j))
}
}
setwd("C:/Users/Veldrin/Documents/GitHub/HelloPeter")
saveRDS(postbody, "Discovery.rds")
require(RCurl)
require(XML)
require(wordcloud)
trim.leading <- function (x)  sub("^\\s+", "", x)
trim.trailing <- function (x) sub("\\s+$", "", x)
cleanFun <- function(htmlString) {
return(gsub("<.*?>", "", htmlString))
}
hp <- c()
link <- data.frame()
title <- data.frame()
time <- data.frame()
type <- data.frame()
postbody <- data.frame()
txt <- "\\(Supplier name changed from.*\\)"
hp[1] <- httpGET("http://hellopeter.com/discovery-insure/compliments-and-complaints?country=South%20Africa&pg=1")
#gets last page
lpsnippet <- substring(hp[1], gregexpr(">>", hp[1])[[1]][1], gregexpr(">>", hp[1])[[1]][2])
a <- as.numeric(regexpr("pg=",lpsnippet)[[1]] + attr(gregexpr("pg=",lpsnippet)[[1]], "match.length"))
b <- min(gregexpr("\"",lpsnippet)[[1]][which(gregexpr("\"",lpsnippet)[[1]] > gregexpr("pg=",lpsnippet)[[1]][1])]) -1
pages <- as.numeric(substring(lpsnippet, a, b))
for (i in 2:pages){
hp[i] <- httpGET(paste("http://hellopeter.com/discovery-insure/compliments-and-complaints?country=South%20Africa&pg=", i, sep = ""))
print(i)
}
# Run this
for (i in 1:pages) {
linklocations <- gregexpr("<div class=\"td-item2\"><a class=\"fb-link\"", hp[i])
for (j in 1:length(linklocations[[1]])) {
#gets URL
snippet <- substring(hp[i],
linklocations[[1]][j],
if (j == length(linklocations[[1]])) nchar(hp[i]) else linklocations[[1]][j+1])
# Link
link[j,i] <- substring(snippet, gregexpr("href=\"",snippet)[[1]][1] + 6,gregexpr(" title=\"",snippet)[[1]][1]-2)
# Title
a <- gregexpr("title=\"",snippet)[[1]][1] + 7
b <- min(gregexpr("\">",snippet)[[1]][which(gregexpr("\">",snippet)[[1]] > gregexpr("title=\"",snippet)[[1]][1] + 7)])-1
title[j,i] <- substring(snippet, a, b)
# Time of post
a <- gregexpr("\">\t",snippet)[[1]][1] + 7
b <- min(gregexpr("\t",snippet)[[1]][which(gregexpr("\t",snippet)[[1]] > gregexpr("\">\t",snippet)[[1]][1] + 7)])-1
time[j,i] <- as.character(as.Date(trim.leading(substring(snippet, a, b)), format = "%H:%M:%S %A %d %b %y"))
# Type of post
if (regexpr("complaints/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Complaint"
if (regexpr("complaints-to-compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Convertion"
if (regexpr("compliments/", link[j,i], ignore.case = T) != -1) type[j,i] <- "Compliment"
# Downloads post
if (!is.na(link[j,i])) {
post <- httpGET(link[j,i])
a <- gregexpr("shade border justify\">", post)
b <- gregexpr("<div class=\"report-action\">", post)
postbody[j,i] <- cleanFun(substring(post, a[[1]][1] + attr(a[[1]], "match.length"), b[[1]][1]-1))
}
#remove name changes strings
if (gregexpr(txt, postbody[j,i]) != -1) {
to.remove <- substring(postbody[j,i],
gregexpr(txt,postbody[j,i])[[1]][1],
gregexpr(txt,postbody[j,i])[[1]][1] + attr(gregexpr(txt,postbody[j,i])[[1]], "match.length") -1)
postbody[j,i] <- gsub(to.remove, "", postbody[j,i])
postbody[j,i] <- gsub("\t", "",gsub("\n", "", postbody[j,i]))
}
print(c(i,j))
}
}
setwd("C:/Users/Veldrin/Documents/GitHub/HelloPeter")
saveRDS(postbody, "DiscoveryInsure.rds")
